# video_generator.py

"""
è§†é¢‘ç”Ÿæˆæ¨¡å— (å·²ç§»é™¤ LangChain)
================================
è¯¥æ¨¡å—åŒ…å«VideoGeneratorç±»ï¼Œè´Ÿè´£å°†æ–‡æœ¬ç« èŠ‚è½¬æ¢ä¸ºå¯è§†åŒ–è§†é¢‘ã€‚
å…¶å·¥ä½œæµç¨‹åŒ…æ‹¬ï¼š
1. ä½¿ç”¨Gemini APIå°†ç« èŠ‚æ–‡æœ¬åˆ†è§£ä¸ºä¸€ç³»åˆ—å¯è§†åŒ–åœºæ™¯ã€‚
2. é€šè¿‡WebSocket APIä¸ComfyUIæœåŠ¡é€šä¿¡ï¼Œä¸ºæ¯ä¸ªåœºæ™¯ç”Ÿæˆè§†é¢‘ç‰‡æ®µã€‚
3. ä½¿ç”¨moviepyå°†æ‰€æœ‰è§†é¢‘ç‰‡æ®µæ‹¼æ¥æˆä¸€ä¸ªå®Œæ•´çš„è§†é¢‘ã€‚
"""

import json
import time
import uuid
import requests
import websocket
from pathlib import Path
from typing import List, Optional, Dict

import google.generativeai as genai
from pydantic import BaseModel, Field
from moviepy.editor import VideoFileClip, concatenate_videoclips
from termcolor import colored

# --- Pydantic æ¨¡å‹å®šä¹‰ ---

class Scene(BaseModel):
    """å®šä¹‰è§†é¢‘æ•…äº‹æ¿çš„å•ä¸ªåœºæ™¯"""
    scene_description: str = Field(..., description="å¯¹è¿™ä¸ªåœºæ™¯çš„ç®€çŸ­æ–‡æœ¬æè¿°ï¼Œæ¦‚æ‹¬å‘ç”Ÿäº†ä»€ä¹ˆã€‚")
    visual_prompt: str = Field(..., description="ä¸€ä¸ªä¸ºAIè§†é¢‘ç”Ÿæˆæ¨¡å‹ä¼˜åŒ–çš„ã€è¯¦ç»†çš„è§†è§‰æç¤ºè¯ã€‚åº”åŒ…å«ä¸»ä½“ã€åŠ¨ä½œã€ç¯å¢ƒã€é£æ ¼ç­‰ã€‚")

class ChapterScenes(BaseModel):
    """åŒ…å«ä¸€ä¸ªç« èŠ‚æ‰€æœ‰åœºæ™¯çš„åˆ—è¡¨"""
    scenes: List[Scene]

# --- æœåŠ¡ç±» ---

class VideoGenerator:
    """å¤„ç†æ‰€æœ‰ä¸è§†é¢‘ç”Ÿæˆç›¸å…³çš„ä»»åŠ¡ (ä½¿ç”¨ google-generativeai)"""
    def __init__(self, api_key: str, comfyui_address: str, workflow_path: Path):
        genai.configure(api_key=api_key)
        self.model_name = "gemini-1.5-pro-latest"
        self.generation_config = genai.GenerationConfig(response_mime_type="application/json")
        
        self.server_address = comfyui_address
        self.client_id = str(uuid.uuid4())
        
        if not workflow_path.exists():
            raise FileNotFoundError(f"ComfyUIå·¥ä½œæµæ–‡ä»¶æœªæ‰¾åˆ°: {workflow_path}")
        self.base_workflow = json.loads(workflow_path.read_text(encoding='utf-8'))

    def _create_prompt(self, system_instruction: str, user_content: str, schema: Dict) -> str:
        """åˆ›å»ºä¸€ä¸ªåŒ…å«JSON schemaçš„å®Œæ•´æç¤ºè¯"""
        return f"{system_instruction}\n\nè¯·ä¸¥æ ¼æŒ‰ç…§ä¸‹é¢çš„JSON Schemaæ ¼å¼è¿”å›ä½ çš„åˆ†æç»“æœ:\n{json.dumps(schema, indent=2)}\n\néœ€è¦åˆ†æçš„æ–‡æœ¬å¦‚ä¸‹:\n---\n{user_content}"

    def split_chapter_into_scenes(self, chapter_text: str) -> Optional[ChapterScenes]:
        """ä½¿ç”¨LLMå°†ç« èŠ‚æ–‡æœ¬åˆ†å‰²æˆä¸€ç³»åˆ—å¯è§†åŒ–åœºæ™¯"""
        model = genai.GenerativeModel(self.model_name, generation_config=self.generation_config)
        system_instruction = """ä½ æ˜¯ä¸€ä½ç”µå½±å¯¼æ¼”å’Œæ•…äº‹æ¿ç”»å¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ä¸‹é¢çš„ç« èŠ‚æ–‡æœ¬åˆ†è§£æˆä¸€ç³»åˆ—ç‹¬ç«‹çš„ã€å¯è§†åŒ–çš„åœºæ™¯ã€‚
            å¯¹äºæ¯ä¸ªåœºæ™¯ï¼Œå®Œæˆä¸¤ä»¶äº‹ï¼š
            1.  `scene_description`: ç”¨ä¸€å¥è¯ç®€è¦æè¿°è¿™ä¸ªåœºæ™¯çš„æ ¸å¿ƒå†…å®¹ã€‚
            2.  `visual_prompt`: åˆ›ä½œä¸€ä¸ªè¯¦ç»†ã€ç”ŸåŠ¨çš„æç¤ºè¯ï¼Œä¾›AIè§†é¢‘ç”Ÿæˆæ¨¡å‹ä½¿ç”¨ã€‚è¿™ä¸ªæç¤ºè¯åº”è¯¥åŒ…å«åœºæ™¯ã€è§’è‰²ã€åŠ¨ä½œã€æƒ…ç»ªå’Œè‰ºæœ¯é£æ ¼ã€‚ä¾‹å¦‚ï¼š"cinematic shot, Alice falling down a rabbit hole, swirling vortex of colors and objects, surreal, dreamlike, high detail"ã€‚
            ç¡®ä¿åœºæ™¯æ•°é‡åœ¨5åˆ°10ä¸ªä¹‹é—´ï¼Œä»¥ä¿æŒè§†é¢‘èŠ‚å¥ã€‚"""

        print(colored("\nğŸ¬ æ­£åœ¨å°†ç« èŠ‚åˆ†å‰²ä¸ºå¯è§†åŒ–åœºæ™¯...", "cyan"))
        try:
            prompt = self._create_prompt(system_instruction, chapter_text, ChapterScenes.model_json_schema())
            response = model.generate_content(prompt)
            scenes = ChapterScenes.model_validate_json(response.text)
            
            print(colored(f"âœ… æˆåŠŸå°†ç« èŠ‚åˆ†å‰²ä¸º {len(scenes.scenes)} ä¸ªåœºæ™¯ã€‚", "green"))
            return scenes
        except Exception as e:
            print(colored(f"âŒ åœºæ™¯åˆ†å‰²å¤±è´¥: {e}", "red"))
            return None
    
    def _queue_comfyui_prompt(self, prompt_workflow: Dict) -> Dict:
        """å°†ä¸€ä¸ªä»»åŠ¡æ·»åŠ åˆ°ComfyUIé˜Ÿåˆ—ä¸­ï¼Œå¹¶ç­‰å¾…ç»“æœ"""
        ws = websocket.WebSocket()
        ws.connect(f"ws://{self.server_address}/ws?clientId={self.client_id}")
        ws.send(json.dumps({"prompt": prompt_workflow, "client_id": self.client_id}))
        
        print(colored("â³ ç­‰å¾…ComfyUIç”Ÿæˆè§†é¢‘ç‰‡æ®µ...", "yellow"))
        while True:
            out = ws.recv()
            if isinstance(out, str):
                message = json.loads(out)
                if message['type'] == 'executed':
                    ws.close()
                    return message['data']['output']
    
    def _generate_clip_for_scene(self, scene_prompt: str, prompt_node_title: str) -> Optional[Path]:
        """ä½¿ç”¨ComfyUIä¸ºå•ä¸ªåœºæ™¯ç”Ÿæˆè§†é¢‘ç‰‡æ®µ"""
        workflow = json.loads(json.dumps(self.base_workflow))
        target_node_id = next((nid for nid, n in workflow.items() if n.get("_meta", {}).get("title") == prompt_node_title), None)
        
        if not target_node_id:
            raise ValueError(f"åœ¨å·¥ä½œæµä¸­æ‰¾ä¸åˆ°æ ‡é¢˜ä¸º '{prompt_node_title}' çš„èŠ‚ç‚¹ã€‚")
        
        workflow[target_node_id]["inputs"]["text"] = scene_prompt
        outputs = self._queue_comfyui_prompt(workflow)
        
        for node_id in outputs:
            if 'videos' in outputs[node_id]:
                video_data = outputs[node_id]['videos'][0]
                url = f"http://{self.server_address}/view?subfolder={video_data.get('subfolder', '')}&filename={video_data['filename']}"
                response = requests.get(url, stream=True)
                if response.status_code == 200:
                    output_dir = Path("temp_clips")
                    output_dir.mkdir(exist_ok=True)
                    clip_path = output_dir / video_data['filename']
                    clip_path.write_bytes(response.content)
                    print(colored(f"\nâœ… è§†é¢‘ç‰‡æ®µå·²ä¿å­˜: {clip_path}", "green"))
                    return clip_path
        return None

    def _stitch_clips_into_video(self, clip_paths: List[Path], output_filename: str) -> Path:
        """å°†è§†é¢‘ç‰‡æ®µæ‹¼æ¥æˆä¸€ä¸ªå®Œæ•´çš„è§†é¢‘"""
        print(colored("\nğŸï¸ æ­£åœ¨æ‹¼æ¥æ‰€æœ‰è§†é¢‘ç‰‡æ®µ...", "cyan"))
        clips = [VideoFileClip(str(p)) for p in clip_paths]
        final_clip = concatenate_videoclips(clips, method="compose")
        
        output_dir = Path("final_videos")
        output_dir.mkdir(exist_ok=True)
        final_path = output_dir / f"{output_filename}.mp4"
        
        # *** ä¿®æ­£ ***: å°†é”™è¯¯çš„ 'libx24' ä¿®æ­£ä¸ºæ­£ç¡®çš„ 'libx264'
        final_clip.write_videofile(str(final_path), codec="libx264", audio_codec="aac")
        print(colored(f"âœ… æœ€ç»ˆè§†é¢‘å·²ç”Ÿæˆ: {final_path}", "green"))

        for p in clip_paths: p.unlink()
        return final_path

    def create_chapter_video(self, chapter_text: str, output_filename: str = "chapter_video") -> Optional[Path]:
        """åˆ›å»ºç« èŠ‚è§†é¢‘çš„å®Œæ•´æµç¨‹ã€‚"""
        scenes_data = self.split_chapter_into_scenes(chapter_text)
        if not scenes_data or not scenes_data.scenes: return None
        
        clip_paths = []
        for i, scene in enumerate(scenes_data.scenes):
            print(colored(f"\nğŸ¬ æ­£åœ¨ç”Ÿæˆåœºæ™¯ {i+1}/{len(scenes_data.scenes)}: '{scene.scene_description}'", "magenta"))
            clip_path = self._generate_clip_for_scene(scene.visual_prompt, "Prompt_Input_Node")
            if clip_path:
                clip_paths.append(clip_path)

        if not clip_paths:
            print(colored("âŒ æœªèƒ½ç”Ÿæˆä»»ä½•è§†é¢‘ç‰‡æ®µï¼Œæ— æ³•åˆ›å»ºæœ€ç»ˆè§†é¢‘ã€‚", "red"))
            return None
            
        return self._stitch_clips_into_video(clip_paths, output_filename)